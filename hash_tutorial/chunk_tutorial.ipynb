{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a30c4de1-b7a1-4e15-800a-f6e85e39732c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rule_set = ['S/_like(_eve,_carol)/0->abc', 'S/_like(_eve,_alice)/0->adc']\n",
    "# ['S/_like(_eve,_y)/0->aΑ/yc', 'Α/_carol->b', 'Α/_alice->d'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a685edca-8a60-47ac-931f-694991f496df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rule_set = ['S/_like(_eve,_carol)/0->abc', 'S/_like(_eve,_alice)/0->def']\n",
    "# ['S/_like(_eve,_carol)/0->abc', 'S/_like(_eve,_alice)/0->def']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5f836ac6-e780-4fcd-a538-e5936da96c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rule_set = ['S/_p(_eve,_carol)/0->aO/pb', 'S/_p(_eve,_alice)/0->aO/pc']\n",
    "# ['S/_p(_eve,_y)/0->aO/pΟ/y', 'Ο/_carol->b', 'Ο/_alice->c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "b42f222b-29bf-4c51-8c95-4e824149f7c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rule_set = [\n",
    "    'S/_like(_eve,_carol)/0->abc', #   ----- スロット1つ\n",
    "    'S/_like(_eve,_alice)/0->adc', \n",
    "    'S/_follow(_x,_david)/0->R/xefg',# ----- スロット2つ\n",
    "    'S/_follow(_x,_jazz)/0->R/xhfg', \n",
    "    'S/_kick(_david,_carol)/0->otl',# ---- chunk　type 2 により 消える\n",
    "    'S/_kick(_david,_y)/0->A/yl', \n",
    "    'A/_alice->eair', # 何もしない\n",
    "    'A/_bob->fngkwu' # 何もしない\n",
    "]\n",
    "\n",
    "# ['S/_like(_eve,_y)/0->aL/yc', 'L/_carol->b', 'L/_alice->d', \n",
    "#  'S/_follow(_x,_y)/0->R/xZ/yfg', 'Z/_david->e', 'Z/_jazz->h', \n",
    "#  'S/_kick(_david,_carol)/0->otl', \n",
    "#  'S/_kick(_david,_y)/0->A/yl', \n",
    "#  'A/_alice->eair', 'A/_bob->fngkwu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5074244-fb59-4d68-8fe4-d55cafd67242",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rule_set = ['S/_kick(_david,_carol)/0->otl', 'S/_kick(_david,_y)/0->D/ytl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336ca756-f4a7-4326-a49b-d1449222564d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "from difflib import SequenceMatcher\n",
    "import string\n",
    "import random\n",
    "\n",
    "# 意味部門\n",
    "\n",
    "def parse_rule(rule):\n",
    "    parts = rule.split('->')\n",
    "    semantic_structure = parts[0].strip()  # 前半部分を意味構造 -> .strip()は空白部分を削除\n",
    "    form = parts[1].strip()  # 後半部分を意味構造\n",
    "    return semantic_structure, form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b90c0a4-43e5-46f4-a381-f6d62d7376bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clustering_rule_set(rule_set):\n",
    "    word_rule_set = []\n",
    "    for rule in rule_set:\n",
    "        semantic_structure, _ = parse_rule(rule)\n",
    "        # ラベルが S 以外で始まるルールを word_rules に分類\n",
    "        if not semantic_structure.startswith(\"S/\"):\n",
    "            word_rule_set.append(rule)\n",
    "    return word_rule_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41428a91-309e-4f86-8815-906e3d0e9c90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "word_rule_set = clustering_rule_set(rule_set)\n",
    "print(word_rule_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffdd0fca-9b2a-402d-b45a-252cc70841f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S/_kick(_david,_carol)/0->otl', 'S/_kick(_david,_y)/0->D/ytl']\n"
     ]
    }
   ],
   "source": [
    "# 追加した\n",
    "# 実行部分の関数def chunk_learning　において，　単語ルールを削除してる\n",
    "# これをしないと， 関数def transformed_set_form　で エラーする\n",
    "\n",
    "for rule in word_rule_set:\n",
    "       rule_set.remove(rule)\n",
    "print(rule_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975c2534-a177-4267-be59-32a1bf7430a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_semantics(rule_set):\n",
    "    semantic_set = []\n",
    "    for a_rule in rule_set:\n",
    "        a_semantics = parse_rule(a_rule)[0]\n",
    "        semantic_set.append(a_semantics)\n",
    "    return semantic_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57f4ee09-cfc5-4598-96fd-af63d98a44f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S/_kick(_david,_carol)/0', 'S/_kick(_david,_y)/0']\n"
     ]
    }
   ],
   "source": [
    "semantic_set = set_semantics(rule_set)\n",
    "print(semantic_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f2ddd6f-5b04-4244-87e1-52b1d50427df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_semantics_ability(semantic_elements):\n",
    "    # 意味表現を単語単位で分割\n",
    "    return re.findall(r'_[a-zA-Z0-9]+|\\(\\w+\\)|[A-Z]+|/[0-9]', semantic_elements)\n",
    "\n",
    "def split_semantics_process(semantic_set):\n",
    "    split_semantic_elements_set = []\n",
    "    for a_semantic_element in semantic_set:\n",
    "        one_of_semantic_set = split_semantics_ability(a_semantic_element)\n",
    "        split_semantic_elements_set.append(one_of_semantic_set)\n",
    "    return split_semantic_elements_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed88c4d-4b47-43e5-ad74-3ebebc3466d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['S', '_kick', '_david', '_carol', '/0'], ['S', '_kick', '_david', '_y', '/0']]\n"
     ]
    }
   ],
   "source": [
    "split_semantic_elements_set = split_semantics_process(semantic_set)\n",
    "print(split_semantic_elements_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f68751c-1df4-4650-af01-df9cc80998f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_sem_difference_ability(split_sem1, split_sem2):\n",
    "    differences = 0\n",
    "    # 2つのリストのうち短い方の長さに合わせてループを回す\n",
    "    min_length = min(len(split_sem1), len(split_sem2))\n",
    "    for i in range(min_length): \n",
    "        if split_sem1[i] != split_sem2[i]:\n",
    "            differences += 1\n",
    "    # もしリストの長さが異なる場合、その分も差異としてカウントする\n",
    "    differences += abs(len(split_sem1) - len(split_sem2))\n",
    "    return differences\n",
    "\n",
    "def count_sem_difference_process(split_semantic_elements_set):\n",
    "    pairs_with_differences = []\n",
    "    \n",
    "    split_sem_1_2_pairs = list(itertools.combinations(split_semantic_elements_set, 2))\n",
    "    for split_sem1, split_sem2 in split_sem_1_2_pairs:\n",
    "        differences = count_sem_difference_ability(split_sem1, split_sem2)\n",
    "        pairs_with_differences.append((split_sem1, split_sem2, differences))\n",
    "    return pairs_with_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56ce6a9e-4b77-4ad8-9747-fa20932a6bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['S', '_kick', '_david', '_carol', '/0'], ['S', '_kick', '_david', '_y', '/0'], 1)]\n"
     ]
    }
   ],
   "source": [
    "pairs_with_differences = count_sem_difference_process(split_semantic_elements_set)\n",
    "print(pairs_with_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb15488-b79e-4b37-a1d1-946999fe52aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_sem_pairs_with_only_one_difference(split_semantic_elements_set):\n",
    "    detect_sem_pairs_with_only_one_difference = []\n",
    "    \n",
    "    split_sem_1_2_pairs = list(itertools.combinations(split_semantic_elements_set, 2))\n",
    "    for split_sem1, split_sem2 in split_sem_1_2_pairs:\n",
    "        differences = count_sem_difference_ability(split_sem1, split_sem2)\n",
    "        if differences == 1:\n",
    "            detect_sem_pairs_with_only_one_difference.append((split_sem1, split_sem2, differences))\n",
    "    return detect_sem_pairs_with_only_one_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1adb607-5dcd-4874-a7b3-55ad2b5235b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['S', '_kick', '_david', '_carol', '/0'], ['S', '_kick', '_david', '_y', '/0'], 1)]\n"
     ]
    }
   ],
   "source": [
    "detect_sem_pairs_with_only_one_difference = detect_sem_pairs_with_only_one_difference(split_semantic_elements_set)\n",
    "print(detect_sem_pairs_with_only_one_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee1e7b-7678-4898-9656-65efe7d1eef1",
   "metadata": {},
   "source": [
    "# 形式部門"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68ed672e-34a5-4069-9f84-c56fdf947316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transformed_set_form(can_chunk_semantic_form_pairs, rule_set):\n",
    "    # can_chunk_semantic_form_pairs  = detect_sem_pairs_with_only_one_difference\n",
    "    # ルールセットを辞書に変換 : 各ルールの左辺をキー、右辺を値とします\n",
    "    rule_dict = {}\n",
    "    for a_rule in rule_set:\n",
    "        key, value = a_rule.split(\"->\")\n",
    "        rule_dict[key] = value\n",
    "\n",
    "    transformed_form_pairs = []\n",
    "    for left, right, _ in can_chunk_semantic_form_pairs:\n",
    "        left_form = f\"{left[0]}/{left[1]}({left[2]},{left[3]}){left[4]}\"\n",
    "        right_form = f\"{right[0]}/{right[1]}({right[2]},{right[3]}){right[4]}\"\n",
    "        \n",
    "        # 変換された文字列から記号列を取得\n",
    "        left_transformed_form = rule_dict.get(left_form, \"\")\n",
    "        right_transformed_form = rule_dict.get(right_form, \"\")\n",
    "\n",
    "        if left_transformed_form and right_transformed_form:\n",
    "            transformed_form_pairs.append((left_transformed_form, right_transformed_form))\n",
    "\n",
    "    return transformed_form_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d6ecd34-060b-414f-b5b5-d338c615b6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('otl', 'D/ytl')]\n"
     ]
    }
   ],
   "source": [
    "transformed_form_pairs = transformed_set_form(detect_sem_pairs_with_only_one_difference, rule_set)\n",
    "print(transformed_form_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "264356bb-cb0c-4714-9260-f1f4c776c762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_form(form):\n",
    "    # 正規表現で「大文字 + スラッシュ + 小文字 (x, y, p)」をひとつの塊として扱う\n",
    "    pattern = re.compile(r'([A-ZΑ-Ω])/(x|y|p)')\n",
    "    \n",
    "    # 見つかった部分を一時的に特殊文字で置き換える\n",
    "    processed_form = form\n",
    "    matches = pattern.findall(form)\n",
    "    replaced_parts = []\n",
    "    \n",
    "    for match in matches:\n",
    "        # 例えば「W/x」を特殊なトークンに置き換える (例: \"_XYP0_\")\n",
    "        part = f\"{match[0]}/{match[1]}\"\n",
    "        token = f\"_XYP{len(replaced_parts)}_\"\n",
    "        processed_form = processed_form.replace(part, token, 1)\n",
    "        replaced_parts.append((token, part))\n",
    "    \n",
    "    return processed_form, replaced_parts\n",
    "\n",
    "def postprocess_form(processed_form, replaced_parts):\n",
    "    # 特殊トークンを元のカテゴリーラベルセットに戻す\n",
    "    for token, original in replaced_parts:\n",
    "        processed_form = processed_form.replace(token, original)\n",
    "    return processed_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "565a8b55-d9c1-4d34-ac91-81ea9b28a2fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # トークンを含む要素を分割して、それぞれを独立した要素にする\n",
    "def split_token_parts(split_form):\n",
    "    final_split_form = []\n",
    "    for part in split_form:\n",
    "        # 特殊トークンを含んでいる部分を見つけたら、その前後の部分と分割\n",
    "        if \"_XYP\" in part:\n",
    "            parts = re.split(r'(_XYP\\d+_)', part)\n",
    "            final_split_form.extend([p for p in parts if p])  # 空要素を除外\n",
    "        else:\n",
    "            final_split_form.append(part)\n",
    "    return final_split_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9166156d-af39-4145-9fb2-ab025bbf8ede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_form_sim_diff_ability(a_form1, a_form2):\n",
    "    # まずはフォームを前処理して、カテゴリーラベルセットを特殊トークンに置き換える\n",
    "    processed_form1, replaced_parts1 = preprocess_form(a_form1)\n",
    "    processed_form2, replaced_parts2 = preprocess_form(a_form2)\n",
    "\n",
    "    # SequenceMatcher で比較\n",
    "    matcher = SequenceMatcher(None, processed_form1, processed_form2)\n",
    "    split_form1 = []\n",
    "    split_form2 = []\n",
    "\n",
    "    # get_opcodes()の出力を確認\n",
    "    opcodes = matcher.get_opcodes()\n",
    "    for tag, i1, i2, j1, j2 in opcodes:\n",
    "        part1 = processed_form1[i1:i2]\n",
    "        part2 = processed_form2[j1:j2]\n",
    "\n",
    "        if tag == 'equal':\n",
    "            split_form1.append(part1)\n",
    "            split_form2.append(part2)\n",
    "        elif tag == 'replace':\n",
    "            split_form1.append(part1)\n",
    "            split_form2.append(part2)\n",
    "        elif tag == 'delete':\n",
    "            split_form1.append(part1)\n",
    "            split_form2.append('')\n",
    "        elif tag == 'insert':\n",
    "            split_form1.append('')\n",
    "            split_form2.append(part2)\n",
    "\n",
    "    # 空の部分集合を削除\n",
    "    split_form1 = [part for part in split_form1 if part]\n",
    "    split_form2 = [part for part in split_form2 if part]\n",
    "    # split_form1 と split_form2 をトークン部分ごとに分割\n",
    "    split_form1 = split_token_parts(split_form1)\n",
    "    split_form2 = split_token_parts(split_form2)\n",
    "\n",
    "    # 結果を元に戻す (トークンを元のカテゴリーラベルセットに復元)\n",
    "    split_form1 = [postprocess_form(part, replaced_parts1) for part in split_form1]\n",
    "    split_form2 = [postprocess_form(part, replaced_parts2) for part in split_form2]\n",
    "\n",
    "    return split_form1, split_form2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b52742ed-335e-4773-9e7d-88837af4d4dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_form_process(transformed_form_pairs):\n",
    "    split_form_pairs = []\n",
    "    for a_form1, a_form2 in transformed_form_pairs:\n",
    "        a_split_form_result = split_form_sim_diff_ability(a_form1, a_form2)\n",
    "        split_form_pairs.append(a_split_form_result)\n",
    "    return split_form_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab83b063-4db4-496b-bebf-8ccd1dbf77ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['o', 'tl'], ['D/y', 'tl'])]\n"
     ]
    }
   ],
   "source": [
    "split_form_pairs = split_form_process(transformed_form_pairs)\n",
    "print(split_form_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85ebe059-5c4b-4a28-9998-97f1dcfdf8ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_forms_by_index_ability(a_form1_as_list, a_form2_as_list): \n",
    "    if len(a_form1_as_list) != len(a_form2_as_list):\n",
    "        return \"2\"\n",
    "    \n",
    "    comparison_form_result_by_index = []\n",
    "    \n",
    "    for index in range(len(a_form1_as_list)):\n",
    "        if a_form1_as_list[index] == a_form2_as_list[index]:\n",
    "            comparison_form_result_by_index.append('0')\n",
    "        else:\n",
    "            comparison_form_result_by_index.append('1')\n",
    "            \n",
    "    return ''.join(comparison_form_result_by_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3dbe29c6-9a96-4fff-8077-19fd7ce98bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_forms_by_index_process(split_form_pairs):\n",
    "    compare_form_pair_results = []\n",
    "    for a_form1_as_list, a_form2_as_list in split_form_pairs:\n",
    "        a_compare_form_pair_result = compare_forms_by_index_ability(a_form1_as_list, a_form2_as_list)\n",
    "        # compare_form_pair_results.append(a_compare_form_pair_result)\n",
    "        compare_form_pair_results.append((a_compare_form_pair_result, a_form1_as_list, a_form2_as_list))  # 各ペアを結果と一緒に保存\n",
    "    return compare_form_pair_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a2a3452-c67c-4309-8b0b-aaa115cd657a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('10', ['o', 'tl'], ['D/y', 'tl'])]\n"
     ]
    }
   ],
   "source": [
    "compare_form_pair_results = compare_forms_by_index_process(split_form_pairs)\n",
    "print(compare_form_pair_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81d99e4a-a213-427d-b400-5a8b8dc1564f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def contains_uppercase_greek_or_latin(character):\n",
    "    # ラテン文字の大文字とギリシア文字の大文字に対するチェック\n",
    "    return character.isupper() or ('Α' <= character <= 'Ω')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d3f578-d787-41e9-92b4-7ad719915eb2",
   "metadata": {},
   "source": [
    "以下は\n",
    "\n",
    "rule_set = ['S/_p(_bob,_david)/0->jQ/p', 'S/_p(_bob,_alice)/0->jU/p']\n",
    "というようなrule_setに対する対処"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a3cd3df-895e-4a06-95b8-1005a3eb6b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_for_uppercase_warning(compare_form_pair_results):\n",
    "    for idx, (result, form1_list, form2_list) in enumerate(compare_form_pair_results):\n",
    "        for i, char in enumerate(result):\n",
    "            if char == '1':  # 差異部分を検出\n",
    "                # form1_list[i] と form2_list[i] に大文字のアルファベットまたはギリシア文字が含まれているか確認\n",
    "                # if contains_uppercase_greek_or_latin(form1_list[i]) or contains_uppercase_greek_or_latin(form2_list[i]):\n",
    "                if any(contains_uppercase_greek_or_latin(c) for c in form1_list[i]) or any(contains_uppercase_greek_or_latin(c) for c in form2_list[i]):\n",
    "                    # print(f\"Warning: Uppercase letter or Greek letter found at index {i} in form pair.\")\n",
    "                    # print(f\"Form1: {form1_list[i]}, Form2: {form2_list[i]}\")\n",
    "                    \n",
    "                    # ここでa_compare_form_pair_result（つまり result）を'2'に変更\n",
    "                    compare_form_pair_results[idx] = ('2', form1_list, form2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c7d0bcf-d934-451e-aa9d-b1fd324c2f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_filtered_indices(compare_form_pair_results): # chunk可能なペアの　indexを所得\n",
    "    filtered_indices_set = []\n",
    "    for index, element in enumerate(compare_form_pair_results):\n",
    "        if (\n",
    "            2 <= len(element) <= 3 and\n",
    "            element.count('1') < 2 and\n",
    "            # '00' not in element and # 同じものが並んでいる　    ---------------------------------ここの条件を外した\n",
    "            # '11' not in element and # 異なるものが並んでいる　   ---------------------------------ここの条件を外した\n",
    "            element != '2' and\n",
    "            not all(c == '0' for c in element)  # すべてが0である場合は対象外\n",
    "        ):\n",
    "            filtered_indices_set.append(index)\n",
    "    return filtered_indices_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dfce4cb6-f195-4488-a845-52b20096fc8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "filtered_indices_set = get_filtered_indices(compare_form_pair_results)\n",
    "print(filtered_indices_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae9fd30-786f-4538-a447-21c1967f176e",
   "metadata": {},
   "source": [
    "# 仕切り直し：chunk可能なペアを，　再度集める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "745bf1f6-48c3-408a-8dba-c798f76a5532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def final_transformed_set_form(can_chunk_semantic_form_pairs, rule_set, filtered_indices_set):\n",
    "    rule_dict = {}\n",
    "    for a_rule in rule_set:\n",
    "        key, value = a_rule.split(\"->\")\n",
    "        rule_dict[key] = value\n",
    "\n",
    "    all_transformed_form_pairs = []\n",
    "    for index in filtered_indices_set:\n",
    "        transformed_form_pairs = []\n",
    "        selected_pair = can_chunk_semantic_form_pairs[index]\n",
    "\n",
    "        left, right, _ = selected_pair\n",
    "        left_form = f\"{left[0]}/{left[1]}({left[2]},{left[3]}){left[4]}\"\n",
    "        right_form = f\"{right[0]}/{right[1]}({right[2]},{right[3]}){right[4]}\"\n",
    "\n",
    "        left_transformed_form = rule_dict.get(left_form, \"\")\n",
    "        right_transformed_form = rule_dict.get(right_form, \"\")\n",
    "\n",
    "        if left_transformed_form:\n",
    "            transformed_form_pairs.append(f\"{left_form}->{left_transformed_form}\")\n",
    "        if right_transformed_form:\n",
    "            transformed_form_pairs.append(f\"{right_form}->{right_transformed_form}\")\n",
    "\n",
    "        all_transformed_form_pairs.append(transformed_form_pairs)\n",
    "\n",
    "    return all_transformed_form_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4a6eee7-a874-467c-bc71-e5aba7739446",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['S/_kick(_david,_carol)/0->otl', 'S/_kick(_david,_y)/0->D/ytl']]\n"
     ]
    }
   ],
   "source": [
    "all_transformed_form_pairs = final_transformed_set_form(detect_sem_pairs_with_only_one_difference, rule_set, filtered_indices_set)\n",
    "print(all_transformed_form_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "482e5901-d466-4c55-a663-0ae8c4d3c962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_only_sem_chunk_pair(can_chunk_rule_set):\n",
    "    transform_only_sem_chunk_pair_sets = []\n",
    "\n",
    "    for a_can_chunk_rule in can_chunk_rule_set:\n",
    "        transformed_a_can_chunk_rule_pair = []\n",
    "        for an_element_of_a_can_chunk_rule in a_can_chunk_rule:\n",
    "            semantic_structure, _ = parse_rule(an_element_of_a_can_chunk_rule)\n",
    "            transformed_a_can_chunk_rule_pair.append(semantic_structure)\n",
    "        transform_only_sem_chunk_pair_sets.append(transformed_a_can_chunk_rule_pair)\n",
    "    \n",
    "    return transform_only_sem_chunk_pair_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f566b258-7519-4d96-90d0-35d3d0ffbb49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['S/_kick(_david,_carol)/0', 'S/_kick(_david,_y)/0']]\n"
     ]
    }
   ],
   "source": [
    "transform_only_sem_chunk_pair_sets = transform_only_sem_chunk_pair(all_transformed_form_pairs)\n",
    "print(transform_only_sem_chunk_pair_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b431bb33-7bdd-4886-b381-507af574c7f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_sem_pairs_for_chunk(sem_chunk_pair_sets):\n",
    "    split_sem_pairs = []\n",
    "    for pair in sem_chunk_pair_sets:\n",
    "        split_pair = []\n",
    "        for semantic_element in pair:\n",
    "            split_element = split_semantics_ability(semantic_element)\n",
    "            split_pair.append(split_element)\n",
    "        split_sem_pairs.append(split_pair)\n",
    "    return split_sem_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4319af7-3956-469d-9d34-089575cb3627",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['S', '_kick', '_david', '_carol', '/0'], ['S', '_kick', '_david', '_y', '/0']]]\n"
     ]
    }
   ],
   "source": [
    "split_sem_pairs = split_sem_pairs_for_chunk(transform_only_sem_chunk_pair_sets)\n",
    "print(split_sem_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8719a1ce-970a-4f51-b85c-540b9a348bda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_index_sem_difference_ability(split_sem1, split_sem2):\n",
    "    differing_indices = []\n",
    "    for i in range(len(split_sem1)): \n",
    "        if split_sem1[i] != split_sem2[i]:\n",
    "            differing_indices.append(i)\n",
    "    return differing_indices\n",
    "\n",
    "def detect_index_sem_difference_process(split_sem_pairs):\n",
    "    index_sem_difference_sets = []\n",
    "    for pair in split_sem_pairs:\n",
    "        if len(pair) < 2:\n",
    "            continue  # もしペアが2つの要素を持たない場合、スキップする\n",
    "        differing_indices = detect_index_sem_difference_ability(pair[0], pair[1])\n",
    "        index_sem_difference_sets.append(differing_indices)\n",
    "    return index_sem_difference_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "561e4984-f682-48b3-8d2d-bde07556bd63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3]]\n"
     ]
    }
   ],
   "source": [
    "index_sem_difference_sets = detect_index_sem_difference_process(split_sem_pairs)\n",
    "print(index_sem_difference_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69fb27f7-4089-4af5-ad71-da4824b927f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform_only_form_chunk_pair(can_chunk_rule_set):\n",
    "    transform_only_form_chunk_pair_sets = []\n",
    "\n",
    "    for a_can_chunk_rule in can_chunk_rule_set:\n",
    "        transformed_a_can_chunk_rule_pair = []\n",
    "        for an_element_of_a_can_chunk_rule in a_can_chunk_rule:\n",
    "            _, form = parse_rule(an_element_of_a_can_chunk_rule)\n",
    "            transformed_a_can_chunk_rule_pair.append(form)\n",
    "        transform_only_form_chunk_pair_sets.append(transformed_a_can_chunk_rule_pair)\n",
    "    \n",
    "    return transform_only_form_chunk_pair_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a784759-7c5f-4c81-a612-73113b432123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['otl', 'D/ytl']]\n"
     ]
    }
   ],
   "source": [
    "transform_only_form_chunk_pair_sets = transform_only_form_chunk_pair(all_transformed_form_pairs)\n",
    "print(transform_only_form_chunk_pair_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4377d709-fad0-4353-aed3-bd337564d9ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_form_process(form_chunk_pair_sets):\n",
    "    split_form_pairs = []\n",
    "    for pair in form_chunk_pair_sets:\n",
    "        if len(pair) != 2:\n",
    "            continue  # 要素数が2でない場合はスキップ\n",
    "        a_form1, a_form2 = pair\n",
    "        a_split_form_result = split_form_sim_diff_ability(a_form1, a_form2)\n",
    "        split_form_pairs.append(a_split_form_result)\n",
    "    return split_form_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c55d03d-519a-4c61-b91b-898db8c1623f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['o', 'tl'], ['D/y', 'tl'])]\n"
     ]
    }
   ],
   "source": [
    "split_form_pairs = split_form_process(transform_only_form_chunk_pair_sets)\n",
    "print(split_form_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "552e8c62-d56e-478d-b624-b27fc8f951c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_index_form_difference_ability(a_form1_as_list, a_form2_as_list): \n",
    "    if len(a_form1_as_list) != len(a_form2_as_list):\n",
    "        return \"長さが異なります\"\n",
    "    \n",
    "    differing_indices = []\n",
    "    \n",
    "    for index in range(len(a_form1_as_list)):\n",
    "        if a_form1_as_list[index] != a_form2_as_list[index]:\n",
    "            differing_indices.append(index)\n",
    "    \n",
    "    return differing_indices\n",
    "\n",
    "def detect_index_form_difference_process(split_form_pairs):\n",
    "    index_form_difference_sets = []\n",
    "    for a_form1_as_list, a_form2_as_list in split_form_pairs:\n",
    "        differing_indices = detect_index_form_difference_ability(a_form1_as_list, a_form2_as_list)\n",
    "        # print(f\"a_form1_as_list: {a_form1_as_list}\")\n",
    "        # print(f\"a_form2_as_list: {a_form2_as_list}\")\n",
    "        # print(f\"differing_indices: {differing_indices}\")\n",
    "        index_form_difference_sets.append(differing_indices)\n",
    "    \n",
    "    return index_form_difference_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53143327-87a4-400e-b240-2f5b2edfa694",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "index_form_difference_sets = detect_index_form_difference_process(split_form_pairs)\n",
    "print(index_form_difference_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30c91a41-7e65-40d6-8617-411f5769ea2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_random_label(used_labels): # どこで used_labelsを取得してる？\n",
    "    # 英字の大文字とギリシャ文字の大文字を定義\n",
    "    greek_uppercase = [\n",
    "        'Α', 'Β', 'Γ', 'Δ', 'Ε', 'Ζ', 'Η', 'Θ', 'Ι', 'Κ', 'Λ', 'Μ',\n",
    "        'Ν', 'Ξ', 'Ο', 'Π', 'Σ', 'Τ', 'Φ', 'Ψ', 'Ω'\n",
    "    ]\n",
    "    \n",
    "    # 英語のアルファベット大文字とギリシャ文字の大文字を組み合わせる\n",
    "    all_labels = list(string.ascii_uppercase) + greek_uppercase\n",
    "    \n",
    "    # 除外する文字\n",
    "    excluded_labels = {'S', 'X', 'Y', 'P'}\n",
    "    \n",
    "    # 使用可能なラベルセットを計算\n",
    "    available_labels = list(set(all_labels) - used_labels - excluded_labels)\n",
    "    # デバッグ: 使用可能なラベルの内容を表示\n",
    "    # 10/1 print(f\"Available labels: {available_labels}\")\n",
    "    \n",
    "    # ランダムに1つのラベルを選択\n",
    "    label = random.choice(available_labels)\n",
    "    \n",
    "    # 使用済みのラベルとして追加\n",
    "    used_labels.add(label)\n",
    "    \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2533951c-3191-4ef7-b56b-e03a920f2161",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_existing_labels_for_type2_chunk(used_labels, split_form_pairs):\n",
    "    for split_form_pair in split_form_pairs:\n",
    "        label_count = {}\n",
    "        for split_form in split_form_pair:\n",
    "            for element in split_form:\n",
    "                if '/' in element:\n",
    "                    label, _ = element.split('/')\n",
    "                    label_count[label] = label_count.get(label, 0) + 1\n",
    "        \n",
    "        # デバッグ: 各ラベルのカウント状況を表示\n",
    "        # print(f\"Label count: {label_count}\")\n",
    "        \n",
    "        for label, count in label_count.items():\n",
    "            if count >= 2:\n",
    "                used_labels.add(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5dc76513-a5c9-4d9b-81f2-f0b65c707e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunk_completed_to_generate_scheme_rules_and_word_rules(\n",
    "    split_sem_pairs,\n",
    "    split_form_pairs,\n",
    "    index_sem_difference_sets,\n",
    "    index_form_difference_sets\n",
    "):\n",
    "    chunk_completed_pairs = []\n",
    "    used_labels = set()\n",
    "    # デバッグ: ラベル適用前の状況を表示\n",
    "    # print(f\"Initial used_labels: {used_labels}\")\n",
    "    \n",
    "    apply_existing_labels_for_type2_chunk(used_labels, split_form_pairs)\n",
    "    # デバッグ: ラベル適用後の状況を表示\n",
    "    # print(f\"Used labels after applying existing labels: {used_labels}\")\n",
    "\n",
    "    index_to_var = {1: '_p', 2: '_x', 3: '_y'}\n",
    "\n",
    "    for sem_pair, form_pair, sem_diff, form_diff in zip(\n",
    "        split_sem_pairs,\n",
    "        split_form_pairs,\n",
    "        index_sem_difference_sets,\n",
    "        index_form_difference_sets\n",
    "    ):\n",
    "        # print(f\"Processing pair: sem_pair={sem_pair}, form_pair={form_pair}\")\n",
    "        # print(f\"sem_diff={sem_diff}, form_diff={form_diff}\")\n",
    "       \n",
    "        existing_label = None\n",
    "        for form_elements in form_pair:\n",
    "            for element in form_elements:\n",
    "                if '/' in element:\n",
    "                    label, _ = element.split('/')\n",
    "                    # 使用済みラベル (2回使われているラベル) を無視\n",
    "                    if label not in used_labels:\n",
    "                        existing_label = label\n",
    "                        break\n",
    "            if existing_label is not None:\n",
    "                break\n",
    "        \n",
    "        # デバッグ: 既存ラベルの確認\n",
    "        # print(f\"Existing label: {existing_label}\")\n",
    "\n",
    "        if existing_label is not None:\n",
    "            label = existing_label\n",
    "            used_labels.add(label)  # 既存ラベルを使用済みラベルに追加\n",
    "        else:\n",
    "            label = generate_random_label(used_labels)\n",
    "        \n",
    "        # デバッグ: 使用されるラベルの確認\n",
    "        # print(f\"Chosen label: {label}\")\n",
    "\n",
    "        index = sem_diff[0]\n",
    "        var = index_to_var.get(index, '_x')\n",
    "\n",
    "        sem_of_scheme_rule = sem_pair[0][:]\n",
    "        sem_of_scheme_rule[index] = var\n",
    "\n",
    "        form_of_scheme_rule = form_pair[0][:]\n",
    "        \n",
    "        # デバッグ用出力: form_diff と form_of_scheme_rule の長さをチェック\n",
    "        # print(f\"form_of_scheme_rule before modification: {form_of_scheme_rule}\")\n",
    "        # print(f\"form_diff: {form_diff}\")\n",
    "        \n",
    "        if form_diff[0] < len(form_of_scheme_rule):\n",
    "            form_of_scheme_rule[form_diff[0]] = f'{label}/{var[1]}'\n",
    "        else:\n",
    "            # print(f\"Error: form_diff[0] is out of bounds for form_of_scheme_rule!\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        form_of_scheme_rule[form_diff[0]] = f'{label}/{var[1]}'  # -----[print]：上のデバッグのために消してる\n",
    "        \n",
    "        scheme_rule = [sem_of_scheme_rule, form_of_scheme_rule]\n",
    "        \n",
    "        sem_of_word_rule_1 = [f'{label}', sem_pair[0][index]]\n",
    "        sem_of_word_rule_2 = [f'{label}', sem_pair[1][index]]\n",
    "\n",
    "        form_of_word_rule_1 = [form_pair[0][form_diff[0]]]\n",
    "        form_of_word_rule_2 = [form_pair[1][form_diff[0]]]\n",
    "\n",
    "        word_rule_1 = [sem_of_word_rule_1, form_of_word_rule_1]\n",
    "        word_rule_2 = [sem_of_word_rule_2, form_of_word_rule_2]\n",
    "\n",
    "        word_rules = []\n",
    "        unwanted_vars = ['_p', '_x', '_y']\n",
    "        for word_rule in [word_rule_1, word_rule_2]:\n",
    "            if not any(var in word_rule[0] for var in unwanted_vars):\n",
    "                word_rules.append(word_rule)\n",
    "\n",
    "        chunk_completed_pairs.append((scheme_rule, *word_rules))\n",
    "        \n",
    "    return chunk_completed_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c4f6a3e-fce9-42d2-a1f6-5e7ff407cdc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([['S', '_kick', '_david', '_y', '/0'], ['D/y', 'tl']], [['D', '_carol'], ['o']])]\n"
     ]
    }
   ],
   "source": [
    "chunk_completed_pairs = chunk_completed_to_generate_scheme_rules_and_word_rules(\n",
    "    split_sem_pairs,\n",
    "    split_form_pairs,\n",
    "    index_sem_difference_sets,\n",
    "    index_form_difference_sets\n",
    ")\n",
    "print(chunk_completed_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52370f38-ff55-477d-ad23-2d1905c2c8a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "can_chunk_rule_set = [['S/_kick(_david,_carol)/0->otl', 'S/_kick(_david,_y)/0->D/ytl']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a3b67cc-9008-4c6f-ab13-ed828851edd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "remaining_rules = rule_set[:]\n",
    "\n",
    "# can_chunk_rule_set に含まれるルールを used_rules に追加\n",
    "used_rules = []\n",
    "for rule_pair in can_chunk_rule_set:\n",
    "    for rule in rule_pair:\n",
    "        # 元の rule_set にあるかを確認し、あれば used_rules に追加\n",
    "        for original_rule in rule_set:\n",
    "            if rule in original_rule:\n",
    "                used_rules.append(original_rule)\n",
    "\n",
    "# 未使用のルールを特定\n",
    "unapplied_rules = [rule for rule in remaining_rules if rule not in used_rules]\n",
    "print(unapplied_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bf0c6c-f45a-4c3d-ac90-e017bd44b364",
   "metadata": {},
   "source": [
    "# 問題あり！　\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9f675e0-b563-4b5c-be0a-00289d040e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S/_kick(_david,_y)/0->D/ytl', 'D/_carol->o']\n"
     ]
    }
   ],
   "source": [
    "chunked_rules = []\n",
    "unapplied_rules = [] \n",
    "word_rule_set = []\n",
    "\n",
    "\n",
    "for scheme_rule, *word_rules in chunk_completed_pairs:\n",
    "        # スキーマルールの整形\n",
    "        sem_scheme_rule = scheme_rule[0]\n",
    "        \n",
    "        # 2番目と3番目の要素をまとめて括弧で囲む\n",
    "        if len(sem_scheme_rule) >= 4:\n",
    "            combined_element = f\"({sem_scheme_rule[2]},{sem_scheme_rule[3]})\"\n",
    "            sem_scheme_rule = sem_scheme_rule[:2] + [combined_element] + sem_scheme_rule[4:]\n",
    "\n",
    "        # スキーマルールを文字列に結合\n",
    "        sem_scheme_rule = f\"{sem_scheme_rule[0]}/\" + \"\".join(sem_scheme_rule[1:])\n",
    "        form_scheme_rule = \"\".join(scheme_rule[1])\n",
    "\n",
    "        chunked_rules.append(f\"{sem_scheme_rule}->{form_scheme_rule}\")\n",
    "        \n",
    "        # 単語ルールの整形\n",
    "        for word_rule in word_rules:\n",
    "            sem_word_rule = \"/\".join(word_rule[0])\n",
    "            form_word_rule = \"\".join(word_rule[1])\n",
    "            chunked_rules.append(f\"{sem_word_rule}->{form_word_rule}\")\n",
    "\n",
    "chunked_rules.extend(unapplied_rules)\n",
    "chunked_rules.extend(word_rule_set)\n",
    "    \n",
    "print(chunked_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "57f13489-392a-4b42-b5c1-f8d8e1556d7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rule_set = [\n",
    "#     'S/_like(_eve,_carol)/0->abc', #   ----- スロット1つ\n",
    "#     'S/_like(_eve,_alice)/0->adc', \n",
    "#     'S/_follow(_x,_david)/0->R/xefg',# ----- スロット2つ\n",
    "#     'S/_follow(_x,_jazz)/0->R/xhfg', \n",
    "#     'S/_kick(_david,_carol)/0->otl',# ---- chunk　type 2 により 消える\n",
    "#     'S/_kick(_david,_y)/0->A/yl', \n",
    "#     'A/_alice->eair', # 何もしない\n",
    "#     'A/_bob->fngkwu' # 何もしない\n",
    "# ]\n",
    "\n",
    "# [['S', '_like', '_eve', '_y', '/0'], ['a', 'N/y', 'c']], [['N', '_carol'], ['b']], [['N', '_alice'], ['d']]\n",
    "# [['S', '_follow', '_x', '_y', '/0'], ['R/x', 'Ο/y', 'fg']], [['Ο', '_david'], ['e']], [['Ο', '_jazz'], ['h']]\n",
    "# [['S', '_kick', '_david', '_y', '/0'], ['A/y', 'l']], [['A', '_carol'], ['ot']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "d21be1aa-b5c1-4890-9307-68247bf36e27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunk_learning(rule_set):\n",
    "    \n",
    "    word_rule_set = clustering_rule_set(rule_set)\n",
    "    for rule in word_rule_set:\n",
    "        rule_set.remove(rule)\n",
    "    # 意味側\n",
    "    semantic_set = set_semantics(rule_set)\n",
    "    split_semantic_elements = split_semantics_process(semantic_set)\n",
    "    can_chunk_semantic_form_pairs = detect_sem_pairs_with_only_one_difference(split_semantic_elements)\n",
    "    \n",
    "    # 形式側\n",
    "    transformed_form_pairs = transformed_set_form(can_chunk_semantic_form_pairs, rule_set)\n",
    "    split_form_pairs = split_form_process(transformed_form_pairs)\n",
    "\n",
    "    # 新しい部分\n",
    "    compare_form_pair_results = compare_forms_by_index_process(split_form_pairs)\n",
    "    check_for_uppercase_warning(compare_form_pair_results)\n",
    "    result_indices = get_filtered_indices([result for result, _, _ in compare_form_pair_results])\n",
    "    \n",
    "    can_chunk_rule_set = final_transformed_set_form(can_chunk_semantic_form_pairs, rule_set, result_indices)\n",
    "\n",
    "    # 各ステップの処理を実行\n",
    "    transform_only_sem_chunk_pairs = transform_only_sem_chunk_pair(can_chunk_rule_set)\n",
    "    \n",
    "    # 変数名を変更して初期化の確認を追加\n",
    "    split_sem_pairs = split_sem_pairs_for_chunk(transform_only_sem_chunk_pairs) if transform_only_sem_chunk_pairs else []\n",
    "\n",
    "    index_sem_difference_sets = detect_index_sem_difference_process(split_sem_pairs)\n",
    "\n",
    "    transform_only_form_chunk_pairs = transform_only_form_chunk_pair(can_chunk_rule_set)\n",
    "    split_form_pairs_for_chunk = split_form_process(transform_only_form_chunk_pairs)\n",
    "    index_form_difference_sets = detect_index_form_difference_process(split_form_pairs_for_chunk)\n",
    "\n",
    "    chunk_completed_pairs = chunk_completed_to_generate_scheme_rules_and_word_rules(\n",
    "        split_sem_pairs,\n",
    "        split_form_pairs_for_chunk,\n",
    "        index_sem_difference_sets,\n",
    "        index_form_difference_sets\n",
    "    )\n",
    "\n",
    "    # ルールセット全体をコピーして保持\n",
    "    remaining_rules = rule_set[:]\n",
    "\n",
    "    # can_chunk_rule_set に含まれるルールを used_rules に追加\n",
    "    used_rules = []\n",
    "    for rule_pair in can_chunk_rule_set:\n",
    "        for rule in rule_pair:\n",
    "            # 元の rule_set にあるかを確認し、あれば used_rules に追加\n",
    "            for original_rule in rule_set:\n",
    "                if rule in original_rule:\n",
    "                    used_rules.append(original_rule)\n",
    "\n",
    "    # 未使用のルールを特定\n",
    "    unapplied_rules = [rule for rule in remaining_rules if rule not in used_rules]\n",
    "\n",
    "    chunked_rules = []\n",
    "\n",
    "    # chunk_completed_to_generate_scheme_rules_and_word_rules_pairs のルールを整形して chunked_rules に追加\n",
    "    for scheme_rule, *word_rules in chunk_completed_pairs:\n",
    "        # スキーマルールの整形\n",
    "        sem_scheme_rule = scheme_rule[0]\n",
    "        \n",
    "        # 2番目と3番目の要素をまとめて括弧で囲む\n",
    "        if len(sem_scheme_rule) >= 4:\n",
    "            combined_element = f\"({sem_scheme_rule[2]},{sem_scheme_rule[3]})\"\n",
    "            sem_scheme_rule = sem_scheme_rule[:2] + [combined_element] + sem_scheme_rule[4:]\n",
    "\n",
    "        # スキーマルールを文字列に結合\n",
    "        sem_scheme_rule = f\"{sem_scheme_rule[0]}/\" + \"\".join(sem_scheme_rule[1:])\n",
    "        form_scheme_rule = \"\".join(scheme_rule[1])\n",
    "\n",
    "        chunked_rules.append(f\"{sem_scheme_rule}->{form_scheme_rule}\")\n",
    "        \n",
    "        # 単語ルールの整形\n",
    "        for word_rule in word_rules:\n",
    "            sem_word_rule = \"/\".join(word_rule[0])\n",
    "            form_word_rule = \"\".join(word_rule[1])\n",
    "            chunked_rules.append(f\"{sem_word_rule}->{form_word_rule}\")\n",
    "\n",
    "    # unapplied_rules を chunked_rules に追加\n",
    "    # word_rule_set を chunked_rules に追加\n",
    "    chunked_rules.extend(unapplied_rules)\n",
    "    chunked_rules.extend(word_rule_set)\n",
    "    \n",
    "    return chunked_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "96801b39-f74a-40be-8094-e866ee3c0f78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[529], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chunked_rules \u001b[38;5;241m=\u001b[39m chunk_learning(rule_set)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(chunked_rules)\n",
      "Cell \u001b[0;32mIn[528], line 9\u001b[0m, in \u001b[0;36mchunk_learning\u001b[0;34m(rule_set)\u001b[0m\n\u001b[1;32m      7\u001b[0m semantic_set \u001b[38;5;241m=\u001b[39m set_semantics(rule_set)\n\u001b[1;32m      8\u001b[0m split_semantic_elements \u001b[38;5;241m=\u001b[39m split_semantics_process(semantic_set)\n\u001b[0;32m----> 9\u001b[0m can_chunk_semantic_form_pairs \u001b[38;5;241m=\u001b[39m detect_sem_pairs_with_only_one_difference(split_semantic_elements)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 形式側\u001b[39;00m\n\u001b[1;32m     12\u001b[0m transformed_form_pairs \u001b[38;5;241m=\u001b[39m transformed_set_form(can_chunk_semantic_form_pairs, rule_set)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "chunked_rules = chunk_learning(rule_set)\n",
    "print(chunked_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca14e2-258a-4e9e-b413-41d26c629c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196e003c-f319-4bbb-8b20-3a0eadbaf8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4975c7d3-8b22-457a-8439-41e3a238174a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b961ab9-a65c-4072-a9ae-c9c80a16391c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c9bb2-c749-43ca-ad04-f3a56831ea95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2994a17-ae48-4b65-b09c-7d130f04066a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd92dd-7309-4eba-b4a0-ddb338fd8654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf1db6-28fa-4d48-8990-6a08c49eced4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a480966-b34c-4253-869d-6691e1059445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
