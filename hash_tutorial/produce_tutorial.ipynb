{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "982d9534-6685-481c-b6c6-8e99c466155e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rule_set = [\n",
    "    \"S/_believe(_ibuki,_quolia)/0->affordance\",\n",
    "    \"S/_help(_alice,_blackawa)/0->communication\",\n",
    "    \"S/_follow(_McKirby,_Kalin)/0->autopoiesis\",\n",
    "    \"S/_love(_x,_koko)/0->jazzT/x\",\n",
    "    \"S/_love(_x,_koko)/0->T/xhiphop\",\n",
    "    \"S/_love(_ibuki,_y)/0->E/yhiphop\",\n",
    "    \"S/_p(_hash,_y)/0->D/ybakabakkaW/p\",\n",
    "    \"S/_p(_x,_y)/0->W/pT/yD/x\",\n",
    "    \"W/_kill->iwrhtb\",\n",
    "    \"D/_ibuki->pow\",\n",
    "    \"T/_blackawa->ljk\"\n",
    "]\n",
    "\n",
    "only_sem_express_set_for_production =[\n",
    "    \"S/_believe(_ibuki,_quolia)/0\", # 全体論的 ：　\" affordance　 \"\n",
    "    \"S/_help(_alice,_blackawa)/0\", # 全体論的 ：　\" communication　 \"\n",
    "    \"S/_believe(_blackawa,_quolia)/0\",# 全部invention\n",
    "    \"S/_help(_ibuki,_quolia)/0\", #  全部invention\n",
    "    \"S/_love(_ibuki,_koko)/0\", # jazz-[invention] or [invention]-hiphop\n",
    "    \"S/_love(_blackawa,_koko)/0\", # jazz-ljk  or  ljk-hiphop\n",
    "    \"S/_kill(_hash,_ibuki)/0\", # pow-bakabakka-iwrhtb\n",
    "    \"S/_kill(_hash,_koko)/0\", # [invention]-bakkabakka-iwrhtb\n",
    "    \"S/_kill(_ibuki,_blackawa)/0\", # iwrhtb-ljk-pow\n",
    "    \"S/_kill(_ibuki,_koko)/0\", # iwrhtb-[invention]-pow\n",
    "    \"S/_help(_ibuki,_koko)/0\", # 全部invention\n",
    "    \"S/_help(_sakana,_koko)/0\", # 全部invention\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cd6b970-a957-4772-80ec-8d481c9968cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "from difflib import SequenceMatcher\n",
    "import string\n",
    "import random\n",
    "\n",
    "# chunkから借用\n",
    "def parse_rule(rule):\n",
    "    parts = rule.split('->')\n",
    "    semantic_structure = parts[0].strip()\n",
    "    form = parts[1].strip()\n",
    "    return semantic_structure, form\n",
    "\n",
    "def set_semantics(rule_set):\n",
    "    semantic_set = []\n",
    "    for a_rule in rule_set:\n",
    "        a_semantics = parse_rule(a_rule)[0]\n",
    "        semantic_set.append(a_semantics)\n",
    "    return semantic_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "678dfded-0dee-4500-8684-b02dd2959e27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clustering_rule_set(rule_set):\n",
    "    holistic_rule_set = []\n",
    "    generalization_rule_set_1 = []\n",
    "    generalization_rule_set_2 = []\n",
    "    generalization_rule_set_3 = []\n",
    "    word_rule_set = []\n",
    "\n",
    "    for rule in rule_set:\n",
    "        semantic_structure, _ = parse_rule(rule)\n",
    "\n",
    "        if not semantic_structure.startswith(\"S/\"):\n",
    "            word_rule_set.append(rule)\n",
    "        else:\n",
    "            p_count = semantic_structure.count(\"_p\")\n",
    "            x_count = semantic_structure.count(\"_x\")\n",
    "            y_count = semantic_structure.count(\"_y\")\n",
    "            total_variables = p_count + x_count + y_count\n",
    "\n",
    "            if total_variables == 0:\n",
    "                holistic_rule_set.append(rule)\n",
    "            elif total_variables == 1:\n",
    "                generalization_rule_set_1.append(rule)\n",
    "            elif total_variables == 2:\n",
    "                generalization_rule_set_2.append(rule)\n",
    "            elif total_variables == 3:\n",
    "                generalization_rule_set_3.append(rule)\n",
    "\n",
    "    return holistic_rule_set, generalization_rule_set_1, generalization_rule_set_2, generalization_rule_set_3, word_rule_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d67c80d8-e01c-465f-8249-558330a665f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_pair_sem_form(rule_set):\n",
    "    pair_sem_form_set = []\n",
    "    for a_rule in rule_set:\n",
    "        a_pair_sem_form = parse_rule(a_rule)\n",
    "        pair_sem_form_set.append(a_pair_sem_form)\n",
    "    return pair_sem_form_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40689276-b404-42fe-b5e2-cc1d350731f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_pair_sem_form_for_word_rule(rule_set):\n",
    "    pair_sem_form_set = []\n",
    "    for a_rule in rule_set:\n",
    "        pair_sem_form_set.append(a_rule)\n",
    "    return pair_sem_form_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94e14cac-d1fe-4912-a109-3842de0eb5f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_rule_sets(rule_set):\n",
    "    holistic_rule_set, generalization_rule_set_1, generalization_rule_set_2, generalization_rule_set_3, word_rule_set = clustering_rule_set(rule_set)\n",
    "\n",
    "    holistic_rule_set = set_pair_sem_form(holistic_rule_set)\n",
    "    variable_1_pair_sem_form_set = set_pair_sem_form(generalization_rule_set_1)\n",
    "    variable_2_pair_sem_form_set = set_pair_sem_form(generalization_rule_set_2)\n",
    "    variable_3_pair_sem_form_set = set_pair_sem_form(generalization_rule_set_3)\n",
    "    word_rule_set = set_pair_sem_form_for_word_rule(word_rule_set)\n",
    "\n",
    "    return holistic_rule_set, variable_1_pair_sem_form_set, variable_2_pair_sem_form_set, variable_3_pair_sem_form_set, word_rule_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e561ed2-bba2-4b89-9e4a-7306f6d68c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_semantics_ability(semantic_elements):\n",
    "    return re.findall(r'_[a-zA-Z0-9]+|\\(\\w+\\)|[A-Z]+|/[0-9]', semantic_elements)\n",
    "\n",
    "def split_semantics_process_for_rule_set(semantic_set):\n",
    "    split_semantic_elements_set_in_rule_set = []\n",
    "    for a_semantic_element in semantic_set:\n",
    "        a_sem_express = a_semantic_element[0]\n",
    "        a_form_express = a_semantic_element[1]\n",
    "        split_semantics = split_semantics_ability(a_sem_express)\n",
    "        split_semantic_elements_set_in_rule_set.append([split_semantics, [a_form_express]])\n",
    "    return split_semantic_elements_set_in_rule_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24282258-b63c-4c91-b51d-1812147f9e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_semantics_process(semantic_set):\n",
    "    split_semantic_elements_set = []\n",
    "    for a_semantic_element in semantic_set:\n",
    "        one_of_semantic_set = split_semantics_ability(a_semantic_element)\n",
    "        split_semantic_elements_set.append(one_of_semantic_set)\n",
    "    return split_semantic_elements_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117dc15f-ca2e-4a91-92ff-f8985a07b99c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_semantic_elements(rule_set):\n",
    "    holistic_rule_set, variable_1_pair_sem_form_set, variable_2_pair_sem_form_set, variable_3_pair_sem_form_set, word_rule_set = initialize_rule_sets(rule_set)\n",
    "\n",
    "    split_semantic_elements_set_in_holistic_rule_set = split_semantics_process_for_rule_set(holistic_rule_set)\n",
    "    split_semantic_elements_set_in_generalization_rule_set_1 = split_semantics_process_for_rule_set(variable_1_pair_sem_form_set)\n",
    "    split_semantic_elements_set_in_generalization_rule_set_2 = split_semantics_process_for_rule_set(variable_2_pair_sem_form_set)\n",
    "    split_semantic_elements_set_in_generalization_rule_set_3 = split_semantics_process_for_rule_set(variable_3_pair_sem_form_set)\n",
    "\n",
    "    return split_semantic_elements_set_in_holistic_rule_set, split_semantic_elements_set_in_generalization_rule_set_1, split_semantic_elements_set_in_generalization_rule_set_2, split_semantic_elements_set_in_generalization_rule_set_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5b3f762-b3da-4caa-ae4d-82c2e2d3dca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_sem_difference_ability(split_sem1, split_sem2):\n",
    "    sem_differences = 0\n",
    "    for sem_element1, sem_element2 in zip(split_sem1, split_sem2):\n",
    "        if sem_element1 != sem_element2:\n",
    "            sem_differences += 1\n",
    "    return sem_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9a896c6-c814-4fcf-bb65-91767c350872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_production_sem_with_any_rule_set_ability(a_split_semantic_elements_set_in_production, any_rule_set, allowed_variables):\n",
    "    variables = []\n",
    "    if not any_rule_set:\n",
    "        return variables\n",
    "    \n",
    "    for an_element_in_any_rule_set in any_rule_set:\n",
    "        number_of_variables = count_sem_difference_ability(a_split_semantic_elements_set_in_production, an_element_in_any_rule_set[0])\n",
    "        if number_of_variables == allowed_variables:\n",
    "            variables.append((an_element_in_any_rule_set, a_split_semantic_elements_set_in_production, number_of_variables))\n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5e63a1e-a1bb-4de0-b3cd-74042a473ff6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pairing_production_and_rules_with_any_variables_process(\n",
    "    split_semantic_elements_set_in_production,\n",
    "    split_semantic_elements_set_in_holistic_rule_set,\n",
    "    split_semantic_elements_set_in_generalization_rule_set_1,\n",
    "    split_semantic_elements_set_in_generalization_rule_set_2,\n",
    "    split_semantic_elements_set_in_generalization_rule_set_3\n",
    "):\n",
    "    any_diff_in_sem_pairs = []\n",
    "    \n",
    "    for a_split_semantic_elements_set_in_production in split_semantic_elements_set_in_production:\n",
    "        \n",
    "        holistic_pairs = compare_production_sem_with_any_rule_set_ability(a_split_semantic_elements_set_in_production, split_semantic_elements_set_in_holistic_rule_set, 0)\n",
    "        if holistic_pairs:\n",
    "            any_diff_in_sem_pairs.append(holistic_pairs)\n",
    "            continue\n",
    "        \n",
    "        variable1_pairs = compare_production_sem_with_any_rule_set_ability(a_split_semantic_elements_set_in_production, split_semantic_elements_set_in_generalization_rule_set_1, 1)\n",
    "        if variable1_pairs:\n",
    "            any_diff_in_sem_pairs.append(variable1_pairs)\n",
    "            continue\n",
    "        \n",
    "        variable2_pairs = compare_production_sem_with_any_rule_set_ability(a_split_semantic_elements_set_in_production, split_semantic_elements_set_in_generalization_rule_set_2, 2)\n",
    "        if variable2_pairs:\n",
    "            any_diff_in_sem_pairs.append(variable2_pairs)\n",
    "            continue\n",
    "        \n",
    "        variable3_pairs = compare_production_sem_with_any_rule_set_ability(a_split_semantic_elements_set_in_production, split_semantic_elements_set_in_generalization_rule_set_3, 3)\n",
    "        if variable3_pairs:\n",
    "            any_diff_in_sem_pairs.append(variable3_pairs)\n",
    "            continue\n",
    "        \n",
    "        any_diff_in_sem_pairs.append(a_split_semantic_elements_set_in_production)\n",
    "    \n",
    "    return any_diff_in_sem_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b5758e4-d994-4d5a-afef-811328b5db64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cluster_any_diff_in_sem_pairs(any_diff_in_sem_pairs):\n",
    "    # 発話指令のみを格納するリスト\n",
    "    only_command_list = []\n",
    "    # 発話指令以外（3つの要素がある）のリスト\n",
    "    command_with_info_list = []\n",
    "    \n",
    "    for item in any_diff_in_sem_pairs:\n",
    "        if isinstance(item, list) and all(isinstance(elem, str) for elem in item):\n",
    "            only_command_list.append(item)\n",
    "        else:\n",
    "            command_with_info_list.append(item)\n",
    "    \n",
    "    return only_command_list, command_with_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a936ddc4-a528-4fac-b9d8-be01f2cadacd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def form_random_generation_ability(length):\n",
    "    allowed_characters = ''.join(c for c in string.ascii_lowercase if c not in 'spxy')\n",
    "    return ''.join(random.choice(allowed_characters) for _ in range(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70277b26-ca31-4448-b22f-4edb29949c26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def form_one_two_three_generation_ability(word_rule_invention_length):\n",
    "    return form_random_generation_ability(random.randint(1, word_rule_invention_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c16d3643-bbe6-4bf1-b0e7-8e0a539ad874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_invented_rules(utterance_list, holistic_rule_invention_length):\n",
    "    invented_rules_from_only_command_list = []\n",
    "\n",
    "    for utterance in utterance_list:\n",
    "        target_sem_express = '/'.join(utterance[:2])\n",
    "\n",
    "        if len(utterance) > 3:\n",
    "            target_sem_express += '(' + ','.join(utterance[2:-1]) + ')'  # 引数部分を追加\n",
    "        target_sem_express += utterance[-1]  # 最後の部分 (/0)を追加\n",
    "        \n",
    "        full_invention = form_random_generation_ability(random.randint(3, holistic_rule_invention_length))\n",
    "        invented_rule = f\"{target_sem_express}->{full_invention}\"\n",
    "        invented_rules_from_only_command_list.append(invented_rule)\n",
    "    \n",
    "    return invented_rules_from_only_command_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ace1a960-7f43-4bd0-b034-c6a390e6a1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_different_elements_and_format_ability(any_diff_in_sem_pair):\n",
    "    list1, list2, _ = any_diff_in_sem_pair\n",
    "\n",
    "    list1_flat = [item for sublist in list1 for item in sublist]\n",
    "    list2_flat = list2\n",
    "\n",
    "    differences = []\n",
    "    formatted_results = []\n",
    "    variable_and_sem_express_pairs = []\n",
    "\n",
    "    for i in range(len(list2_flat)):\n",
    "        if list1_flat[i] != list2_flat[i]:\n",
    "            if not list1_flat[i].startswith('_'):\n",
    "                differences.append(list1_flat[i])\n",
    "            differences.append(list2_flat[i])\n",
    "\n",
    "            if list1_flat[i].startswith('_'):\n",
    "                variable = list1_flat[i][1]\n",
    "                for sublist in list1:\n",
    "                    for item in sublist:\n",
    "                        if variable in item:\n",
    "                            index = item.index(variable)\n",
    "                            if index >= 2:\n",
    "                                formatted_item = item[index-2:index] + variable\n",
    "                                formatted_results.append(formatted_item)\n",
    "                                \n",
    "                                formatted_combined = item[index-2:index] + list2_flat[i]\n",
    "                                variable_and_sem_express_pairs.append([variable, formatted_combined])\n",
    "\n",
    "    final_result = formatted_results + differences\n",
    "    return final_result, variable_and_sem_express_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad24e464-c35f-4a1e-9039-c71880543f14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_and_invention_word_rule_ability(variable_and_sem_express_pairs, word_rule_set, word_rule_invention_length):\n",
    "    word_variable_and_sem_express_pairs = []\n",
    "    invented_rules = []\n",
    "    generated_forms = {}\n",
    "    \n",
    "    for pair in variable_and_sem_express_pairs:\n",
    "        matching_rules = []\n",
    "\n",
    "        target_sem_express = pair[1]\n",
    "        \n",
    "        if target_sem_express in generated_forms:\n",
    "            selected_rule = generated_forms[target_sem_express]\n",
    "        else:\n",
    "            for rule in word_rule_set:\n",
    "                sem_express_in_rule = rule.split('->')[0]\n",
    "                if sem_express_in_rule == target_sem_express:\n",
    "                    matching_rules.append(rule)\n",
    "\n",
    "            if len(matching_rules) == 1:\n",
    "                selected_rule = matching_rules[0]\n",
    "            elif len(matching_rules) > 1:\n",
    "                selected_rule = random.choice(matching_rules)\n",
    "            else:\n",
    "                random_word_form = form_one_two_three_generation_ability(word_rule_invention_length)\n",
    "                selected_rule = f\"{target_sem_express}->{random_word_form}\"\n",
    "                invented_rules.append(selected_rule)\n",
    "                generated_forms[target_sem_express] = selected_rule\n",
    "\n",
    "        word_variable_and_sem_express_pairs.append([pair[0], selected_rule])\n",
    "    \n",
    "    return word_variable_and_sem_express_pairs, invented_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12d898a5-386b-4e4d-933b-3edd2febabed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_single_diff_in_sem_pair_ability(any_diff_in_sem_pair, word_rule_set, word_rule_invention_length):\n",
    "    list1, list2, difference_count = any_diff_in_sem_pair\n",
    "\n",
    "    if difference_count == 0:\n",
    "        return list1, [], 0, [], any_diff_in_sem_pair\n",
    "\n",
    "    final_result, variable_and_sem_express_pairs = extract_different_elements_and_format_ability(any_diff_in_sem_pair)\n",
    "    word_variable_and_sem_express_pairs, invented_rules = detect_and_invention_word_rule_ability(variable_and_sem_express_pairs, word_rule_set, word_rule_invention_length)\n",
    "\n",
    "    if len(invented_rules) >= 2:\n",
    "        full_invention = form_random_generation_ability(random.randint(3, 9))\n",
    "        final_result = [full_invention]\n",
    "        word_variable_and_sem_express_pairs = [[var, full_invention] for var, _ in word_variable_and_sem_express_pairs]\n",
    "        invented_rules = []\n",
    "        invention_count = 3\n",
    "    else:\n",
    "        invention_count = len(invented_rules)\n",
    "    \n",
    "    return final_result, word_variable_and_sem_express_pairs, invention_count, invented_rules, any_diff_in_sem_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f51aded6-0fe5-41c1-91a8-d6fd042ccbb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_best_utterance(possible_pairs, word_rule_set, word_rule_invention_length):\n",
    "    best_pair = None\n",
    "    lowest_invented_rule_count = float('inf')\n",
    "    best_invented_rules = []\n",
    "    best_word_variable_and_sem_express_pairs = []\n",
    "\n",
    "    for i, pair in enumerate(possible_pairs):\n",
    "        final_result, word_variable_and_sem_express_pairs, invention_count, invented_rules, _ = process_single_diff_in_sem_pair_ability(pair, word_rule_set, word_rule_invention_length)\n",
    "\n",
    "        if invention_count < lowest_invented_rule_count:\n",
    "            lowest_invented_rule_count = invention_count\n",
    "            best_pair = pair\n",
    "            best_invented_rules = invented_rules\n",
    "            best_word_variable_and_sem_express_pairs = word_variable_and_sem_express_pairs\n",
    "        elif invention_count == lowest_invented_rule_count:\n",
    "            if random.choice([True, False]):\n",
    "                best_pair = pair\n",
    "                best_invented_rules = invented_rules\n",
    "                best_word_variable_and_sem_express_pairs = word_variable_and_sem_express_pairs\n",
    "\n",
    "    return best_pair, best_invented_rules, best_word_variable_and_sem_express_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93eade88-b73c-4d8e-a616-e368af0421fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_and_return_production_ingredients(any_diff_in_sem_pairs, word_rule_set, word_rule_invention_length):\n",
    "    production_ingredients = []\n",
    "\n",
    "    for any_diff_in_sem_pair_group in any_diff_in_sem_pairs:\n",
    "        if isinstance(any_diff_in_sem_pair_group, list) and len(any_diff_in_sem_pair_group) > 1:\n",
    "            best_pair, best_invented_rules, best_word_variable_and_sem_express_pairs = select_best_utterance(any_diff_in_sem_pair_group, word_rule_set, word_rule_invention_length)\n",
    "            final_result, _, _, _, _ = process_single_diff_in_sem_pair_ability(best_pair, word_rule_set, word_rule_invention_length)\n",
    "            \n",
    "            if best_invented_rules:\n",
    "                word_rule_set.extend(best_invented_rules)\n",
    "            \n",
    "            production_ingredient = [best_pair, best_word_variable_and_sem_express_pairs]\n",
    "            production_ingredients.append(production_ingredient)\n",
    "        else:\n",
    "            final_result, best_word_variable_and_sem_express_pairs, _, best_invented_rules, best_pair = process_single_diff_in_sem_pair_ability(any_diff_in_sem_pair_group[0], word_rule_set, word_rule_invention_length)\n",
    "            \n",
    "            if best_invented_rules:\n",
    "                word_rule_set.extend(best_invented_rules)\n",
    "            \n",
    "            production_ingredient = [best_pair, best_word_variable_and_sem_express_pairs]\n",
    "            production_ingredients.append(production_ingredient)\n",
    "\n",
    "    return production_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b9c06d1-51c8-42f0-93e2-1c401a62aa90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_word_and_variable_ability(an_only_one_diff_in_sem_pair, word_variable_and_sem_express_pairs):\n",
    "    meaning_part = an_only_one_diff_in_sem_pair[1]\n",
    "    form_part = an_only_one_diff_in_sem_pair[0][1]\n",
    "    new_meaning = meaning_part[:]\n",
    "    new_form = ''.join(form_part)\n",
    "    \n",
    "    if len(word_variable_and_sem_express_pairs) == 2 and all(pair[1] == word_variable_and_sem_express_pairs[0][1] for pair in word_variable_and_sem_express_pairs):\n",
    "        word_form = word_variable_and_sem_express_pairs[0][1]\n",
    "        return restore_sentence_rule_ability([new_meaning, [word_form]])\n",
    "\n",
    "    for i, element in enumerate(new_meaning):\n",
    "        if element.startswith('_'):\n",
    "            position = element[1]\n",
    "\n",
    "            for var_pos, word_rule in word_variable_and_sem_express_pairs:\n",
    "                if var_pos == position:\n",
    "                    word_meaning, word_form = word_rule.split('->')\n",
    "                    new_meaning[i] = word_meaning.split('/')[1]\n",
    "\n",
    "    for var_pos, word_rule in word_variable_and_sem_express_pairs:\n",
    "        if '->' not in word_rule:\n",
    "            continue\n",
    "        \n",
    "        category_label_and_sem_express, word_meaning_form = word_rule.split('->')\n",
    "        word_form = word_meaning_form\n",
    "        category_label = category_label_and_sem_express.split('/')[0]\n",
    "    \n",
    "        new_form = new_form.replace(f'{category_label}/{var_pos}', word_form)\n",
    "\n",
    "    return restore_sentence_rule_ability([new_meaning, [new_form]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1105f518-01d6-40dd-bee9-ec63c3199823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def restore_sentence_rule_ability(split_sentence_rule):\n",
    "    split_sem_express = split_sentence_rule[0]\n",
    "    \n",
    "    restored_sem_express = split_sem_express[0] + '/' + split_sem_express[1]\n",
    "\n",
    "    if len(split_sem_express) > 3:\n",
    "        restored_sem_express += '(' + ','.join(split_sem_express[2:-1]) + ')'\n",
    "    \n",
    "    restored_sem_express += split_sem_express[-1]\n",
    "    \n",
    "    form_express = split_sentence_rule[1][0]\n",
    "    \n",
    "    return f\"{restored_sem_express}->{form_express}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9369ba68-564d-4ec9-8596-296e69634d53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_sentence_rule(best_pair, word_variable_and_sem_express_pairs):\n",
    "    if not word_variable_and_sem_express_pairs:\n",
    "        meaning_part = best_pair[1]\n",
    "        form_part = best_pair[0][1]\n",
    "        return f\"{meaning_part[0]}/\" + f\"{meaning_part[1]}\" + \"(\" + \",\".join(meaning_part[2:-1]) + \")\" + meaning_part[-1] + \"->\" + \"\".join(form_part)\n",
    "    else:\n",
    "        return combine_word_and_variable_ability(best_pair, word_variable_and_sem_express_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80c21ec6-5bc6-4d1f-9ac1-3470bf4a3005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_all_sentence_rules(production_ingredients):\n",
    "    generated_rules = []\n",
    "    \n",
    "    for pair_and_vars in production_ingredients:\n",
    "        best_pair, word_variable_and_sem_express_pairs = pair_and_vars\n",
    "        rule = generate_sentence_rule(best_pair, word_variable_and_sem_express_pairs)\n",
    "        generated_rules.append(rule)\n",
    "    \n",
    "    return generated_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe09f6cf-4a64-4686-b2c6-5a4c41976bef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 新たに追加する関数\n",
    "def shoten_too_long_form_ability(generated_rules, max_form_length=9, front_keep_length=6):\n",
    "    \"\"\"\n",
    "    形式長が max_form_length 以上の場合に、前半の front_keep_length 文字を残して後ろを切り捨てる関数。\n",
    "    \"\"\"\n",
    "    shortened_rules = []\n",
    "    for rule in generated_rules:\n",
    "        semantic_structure, form = parse_rule(rule)\n",
    "        if len(form) >= max_form_length:\n",
    "            form = form[:front_keep_length]  # 後ろの部分を切り捨て\n",
    "        shortened_rules.append(f\"{semantic_structure}->{form}\")\n",
    "    return shortened_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f5a7787-77cf-4a15-b039-a2b803daa3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce(rule_set, only_sem_express_set_for_production, holistic_rule_invention_length, word_rule_invention_length, max_form_length, front_keep_length):\n",
    "\n",
    "    \"\"\"\n",
    "    言語生成を行うメイン関数。ルールの生成、発明、短縮を行い、最終的に生成されたルールセットを返す。\n",
    "    \"\"\"\n",
    "\n",
    "    # ルールセットの初期化\n",
    "    holistic_rule_set, variable_1_pair_sem_form_set, variable_2_pair_sem_form_set, variable_3_pair_sem_form_set, word_rule_set = initialize_rule_sets(rule_set)\n",
    "\n",
    "    # セマンティック要素を処理\n",
    "    split_semantic_elements_set_in_holistic_rule_set = split_semantics_process_for_rule_set(holistic_rule_set)\n",
    "    split_semantic_elements_set_in_generalization_rule_set_1 = split_semantics_process_for_rule_set(variable_1_pair_sem_form_set)\n",
    "    split_semantic_elements_set_in_generalization_rule_set_2 = split_semantics_process_for_rule_set(variable_2_pair_sem_form_set)\n",
    "    split_semantic_elements_set_in_generalization_rule_set_3 = split_semantics_process_for_rule_set(variable_3_pair_sem_form_set)\n",
    "    \n",
    "    split_semantic_elements_set_in_production = split_semantics_process(only_sem_express_set_for_production)\n",
    "\n",
    "    # セマンティックペアとルールの比較\n",
    "    any_diff_in_sem_pairs = pairing_production_and_rules_with_any_variables_process(\n",
    "        split_semantic_elements_set_in_production,\n",
    "        split_semantic_elements_set_in_holistic_rule_set,\n",
    "        split_semantic_elements_set_in_generalization_rule_set_1,\n",
    "        split_semantic_elements_set_in_generalization_rule_set_2,\n",
    "        split_semantic_elements_set_in_generalization_rule_set_3\n",
    "    )\n",
    "\n",
    "    # 発話指令リストを作成\n",
    "    only_command_list, command_with_info_list = cluster_any_diff_in_sem_pairs(any_diff_in_sem_pairs)\n",
    "\n",
    "    # 新しいルールの発明\n",
    "    invented_rules_from_only_command_list = generate_invented_rules(only_command_list, holistic_rule_invention_length)\n",
    "\n",
    "    # 発話を生成\n",
    "    production_ingredients = process_and_return_production_ingredients(command_with_info_list, word_rule_set, word_rule_invention_length)\n",
    "    generated_rules = generate_all_sentence_rules(production_ingredients)\n",
    "\n",
    "    # 発明されたルールを生成されたルールに追加\n",
    "    generated_rules.extend(invented_rules_from_only_command_list)\n",
    "\n",
    "    # 形式が長すぎる場合に短縮する処理を追加\n",
    "    generated_rules = shoten_too_long_form_ability(generated_rules, max_form_length, front_keep_length)\n",
    "\n",
    "    return generated_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef4c7592-0f9f-4604-b20c-4f5fafd68dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S/_believe(_ibuki,_quolia)/0->afford', 'S/_help(_alice,_blackawa)/0->commun', 'S/_believe(_blackawa,_quolia)/0->W/pT/y', 'S/_help(_ibuki,_quolia)/0->W/pT/y', 'S/_love(_ibuki,_koko)/0->aeehip', 'S/_love(_blackawa,_koko)/0->ljkhip', 'S/_kill(_hash,_ibuki)/0->powbak', 'S/_kill(_hash,_koko)/0->nkebak', 'S/_kill(_ibuki,_blackawa)/0->iwrhtb', 'S/_kill(_ibuki,_koko)/0->iwrhtb', 'S/_help(_ibuki,_koko)/0->bewfpow', 'S/_help(_sakana,_koko)/0->bewflcq']\n"
     ]
    }
   ],
   "source": [
    "holistic_rule_invention_length = 3  # 文全体のルールの最大長さ\n",
    "word_rule_invention_length = 3  # 単語ルールの最大長さ\n",
    "max_form_length = 8  # 形式の最大長さ\n",
    "front_keep_length = 6  # 前半に残す長さ\n",
    "\n",
    "generated_rules = produce(rule_set, only_sem_express_set_for_production, holistic_rule_invention_length, word_rule_invention_length, max_form_length, front_keep_length)\n",
    "print(generated_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f293017-7fb4-4356-8c38-fad58167852d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
